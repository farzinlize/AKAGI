{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "akagi_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "u2-mx9a7hJSO",
        "62y5xLq0qOFS",
        "uNGyKbeIRhKx",
        "tQvIMkWmtk-I",
        "MrvCQTijypjh",
        "UV_q-gTakZ4D"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farzinlize/AKAGI/blob/master/akagi_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYcbj9xP2vOX"
      },
      "source": [
        "# AKAGI - Motif Finding and Analysis Application\n",
        "\n",
        "Akagi is an application to search and find repeated patterns, which have nearly same instances over a set of sequences. Our goal is to find and study hidden DNA patterns that are highly related to a specific binding site. \n",
        "visit our github page for more information: [AKAGI github](https://github.com/farzinlize/AKAGI)\n",
        "\n",
        "Table 1. list of supported AKAGI commands\n",
        "\n",
        "\n",
        "*   `SLD` : single level dataset (cache)\n",
        "  *   options: `kmin`, `kmax` of background Gkmerhood, `level` of graph to cache, `dmax` of maximum search depth\n",
        "* `FLD` : first-level last-level dataset (cache)\n",
        "  * generate cache of all nodes between first-level and last-level\n",
        "*   `MFC` : Motif finding & Chaining (described later in document)\n",
        "*   `SDM` : sequence distance matrix\n",
        "  *   generate distance matrix of every instances of each pattern in fasta format\n",
        "* `ARS` : analysis raw statistics (Tumpa article)\n",
        "* `ALG` : multiple alignment using `muscle` application\n",
        "  * align all instances of a group in fasta format\n",
        "* `CNM` : coloring neighbourhood of motifs (study design)\n",
        "* `2BT` : download genome referneces 2bit-file\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnvDYVIs7MWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b599ec55-7f42-4d8e-86aa-ff246c749de4"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#               AKAGI INSTALLATION                #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "# cloning AKAGI source code hosted at github\n",
        "!git clone https://github.com/farzinlize/AKAGI.git\n",
        "%cd AKAGI\n",
        " \n",
        "# installing AKAGI dependencies\n",
        "''' \n",
        "  python libraries requied by AKAGI:\n",
        "  - biopython\n",
        "  - twobitreader: utilize 2bit compressed genome file\n",
        "  - memory_profiler\n",
        "  - email-to: auto email reports and attachments\n",
        "  - PyDrive: google drive authentication and operations\n",
        "'''\n",
        "!pip install biopython\n",
        "!pip install twobitreader\n",
        "!pip install -U memory_profiler\n",
        "!pip install email-to\n",
        "!pip install PyDrive\n",
        " \n",
        "# downloading datasets from hmchip\n",
        "!mkdir hmchipdata\n",
        "!wget http://jilab.jhsph.edu/database/dataset/Human_hg18_peakcod.tar.gz\n",
        "!tar -xf Human_hg18_peakcod.tar.gz -C ./hmchipdata\n",
        " \n",
        "# downloading human genome references\n",
        "!python app.py 2BT -r hg18\n",
        "\n",
        "# making PFM directory\n",
        "!mkdir pfms \n",
        "\n",
        "'''\n",
        "  [WARNING] PLACE SECRET IN `secret.json` FOR EMAIL-REPORT HERE\n",
        "'''\n",
        "!echo {'\"google_app_password\"':'\"SECRET_PASSWORD\"'} > secret.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AKAGI'...\n",
            "remote: Enumerating objects: 1288, done.\u001b[K\n",
            "remote: Counting objects: 100% (1288/1288), done.\u001b[K\n",
            "remote: Compressing objects: 100% (851/851), done.\u001b[K\n",
            "remote: Total 1288 (delta 697), reused 1022 (delta 431), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1288/1288), 14.16 MiB | 7.35 MiB/s, done.\n",
            "Resolving deltas: 100% (697/697), done.\n",
            "/content/AKAGI\n",
            "Collecting biopython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/cd/0098eaff841850c01da928c7f509b72fd3e1f51d77b772e24de9e2312471/biopython-1.78-cp37-cp37m-manylinux1_x86_64.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.78\n",
            "Collecting twobitreader\n",
            "  Downloading https://files.pythonhosted.org/packages/d5/2c/7278556581fd716eec5e83c095c279e4c9012723f423a527093d8b57f3b3/twobitreader-3.1.7.tar.gz\n",
            "Building wheels for collected packages: twobitreader\n",
            "  Building wheel for twobitreader (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for twobitreader: filename=twobitreader-3.1.7-cp37-none-any.whl size=9605 sha256=a5818b9a592541b37a6a70fc3aa8c212fe9f3979a801f98bea62a0fcf8a83d42\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/19/06/b561af3759c4bd4452864e7aa1a33af2c7e3b5a65710d71de8\n",
            "Successfully built twobitreader\n",
            "Installing collected packages: twobitreader\n",
            "Successfully installed twobitreader-3.1.7\n",
            "Collecting memory_profiler\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/fd/d92b3295657f8837e0177e7b48b32d6651436f0293af42b76d134c3bb489/memory_profiler-0.58.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: psutil in /usr/local/lib/python3.7/dist-packages (from memory_profiler) (5.4.8)\n",
            "Building wheels for collected packages: memory-profiler\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for memory-profiler: filename=memory_profiler-0.58.0-cp37-none-any.whl size=30180 sha256=3db99f85ba8ccee29445f0e211a71c7d3b3b333b6366ccae490fad78a67652ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/e4/0b/aaab481fc5dd2a4ea59e78bc7231bb6aae7635ca7ee79f8ae5\n",
            "Successfully built memory-profiler\n",
            "Installing collected packages: memory-profiler\n",
            "Successfully installed memory-profiler-0.58.0\n",
            "Collecting email-to\n",
            "  Downloading https://files.pythonhosted.org/packages/56/33/3f3a09446b8f8967f98e6df29cdda65d3cc5e40a0f0b6dedf3fd076a60c7/email_to-0.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from email-to) (3.3.4)\n",
            "Collecting premailer\n",
            "  Downloading https://files.pythonhosted.org/packages/d9/02/ba01e611eb82df8be03849de6564851387336c9af24b33b588b809b3d09f/premailer-3.9.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown->email-to) (4.0.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from premailer->email-to) (4.2.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from premailer->email-to) (2.23.0)\n",
            "Collecting cssutils\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/c4/9db28fe567612896d360ab28ad02ee8ae107d0e92a22db39affd3fba6212/cssutils-2.3.0-py3-none-any.whl (404kB)\n",
            "\u001b[K     |████████████████████████████████| 409kB 7.7MB/s \n",
            "\u001b[?25hCollecting cssselect\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.7/dist-packages (from premailer->email-to) (4.2.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown->email-to) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown->email-to) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->premailer->email-to) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->premailer->email-to) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->premailer->email-to) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->premailer->email-to) (2.10)\n",
            "Installing collected packages: cssutils, cssselect, premailer, email-to\n",
            "Successfully installed cssselect-1.1.0 cssutils-2.3.0 email-to-0.1.0 premailer-3.9.0\n",
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (1.12.8)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.7/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: six<2dev,>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.15.0)\n",
            "Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.30.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (1.26.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.2->PyDrive) (0.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.7.2)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (56.1.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.2->PyDrive) (4.2.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.23.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.53.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (20.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.2->PyDrive) (2.4.7)\n",
            "--2021-06-01 07:04:07--  http://jilab.jhsph.edu/database/dataset/Human_hg18_peakcod.tar.gz\n",
            "Resolving jilab.jhsph.edu (jilab.jhsph.edu)... 162.129.45.24\n",
            "Connecting to jilab.jhsph.edu (jilab.jhsph.edu)|162.129.45.24|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1482055680 (1.4G) [application/x-gzip]\n",
            "Saving to: ‘Human_hg18_peakcod.tar.gz’\n",
            "\n",
            "Human_hg18_peakcod. 100%[===================>]   1.38G  88.7MB/s    in 16s     \n",
            "\n",
            "2021-06-01 07:04:23 (89.2 MB/s) - ‘Human_hg18_peakcod.tar.gz’ saved [1482055680/1482055680]\n",
            "\n",
            "[2BIT] downloading reference: hg18[2BIT] completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpJFs4wkx7Be"
      },
      "source": [
        "# AKAGI uninstall:\n",
        "%cd ..\n",
        "!rm -rf AKAGI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bxhr3xOGmal"
      },
      "source": [
        "# AKAGI update\n",
        "!git reset --hard\n",
        "!git pull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGOOQ-PUWg8r"
      },
      "source": [
        "# Email and Cloud authentication\n",
        "\n",
        "For report purposes and utilizing cloud services in order to run experiments, some private tokens are needed as described here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-ypl9tquvRw"
      },
      "source": [
        "## `secret.json` file\n",
        "\n",
        "AKAGI reports contain execution information and predictions and will be sent by email. A json file named `secret.json` (contains sensitive data) is required for this purpose and the best way to insert this data is **to modify the file manually** using *Files* tool in colab from left pannel. Or you can use this cell by putting password instead of `SECRET_PASSWORD` but remember to remove it after running the cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2a2jaUSCkFN"
      },
      "source": [
        "################ WARNING IMPORTANT ########################\n",
        "####  delete the password after running cell for safty ####\n",
        "###########################################################\n",
        "\n",
        "# place the password instead of \"SECRET_PASSWORD\"\n",
        "!echo {'\"google_app_password\"':'\"SECRET_PASSWORD\"'} > secret.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0U9yyvraSvS"
      },
      "source": [
        "# cell for email report use\n",
        "!python report_email.py -i app.py -a constants.py -t T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFlGakZtIgVv"
      },
      "source": [
        "# changing the email address to akagi automail account\n",
        "!python app.py NOP -C \"EMAIL_ACCOUNT='akagi.automail@gmail.com'\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkEK-7N3rZi-"
      },
      "source": [
        "## `client_secret.json`\n",
        "\n",
        "this file is required by `PyDrive` liberary to function \n",
        "\n",
        "### google drive authentication \n",
        "\n",
        "`googledrive.py` module handles google drive based operations by utilizing `PyDrive` liberary. once you run `python gooledrive.py` command, *AKAGI: motif finding* application is able to function with using checkpointes stored at google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnu3JWKg2eMK"
      },
      "source": [
        "!touch client_secrets.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0hqL02urj1E",
        "outputId": "d5cc5771-ffd7-4642-b834-cb25412b4fb6"
      },
      "source": [
        "# run this cell once for a colab session\n",
        "!python googledrive.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=285671014364-v2c9m48chkqi23e33phpoodrjfugjvop.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
            "\n",
            "Enter verification code: 4/1AY0e-g7f2Seh0Qa4PcKxRyf09QogpxMQO6o3czzvYyD0PB-UH2mbZ4KAltM\n",
            "Authentication successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wev14Z3r70ym"
      },
      "source": [
        "# Data preparation\n",
        "\n",
        "special AKAGI operations requires references or pre-processd data to function. `2BT` and `FLD` commands provide necessery data descibed here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwYMKv494XhL"
      },
      "source": [
        "## human genome reference\n",
        "\n",
        "human genome reference hg18 is used to map peak annotation to extract their sequences. `2BT` command is used for downloding available references \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVuuVKi27653",
        "outputId": "414aa756-e725-4922-970e-8f5aa098999f"
      },
      "source": [
        "# downloading human genome reference\n",
        "!python app.py 2BT --reference=hg18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2BIT] downloading reference: hg18[2BIT] completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYl0lyY94dVy"
      },
      "source": [
        "## BFS data Caches\n",
        "\n",
        "an observation phase needed d-neighbourhood of kmers, extracted from sequence through a fixed lentgh window. First a dataset is generated to cache BFS information of gkmerhood nodes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whJMANfoXpKY"
      },
      "source": [
        "'''\n",
        "  levels: 7-8\n",
        "  index: 2 (in `dataset_tree`)\n",
        "  tree name: gkhood78.tree\n",
        "  cache location: /cache78/\n",
        "'''\n",
        "!python app.py FLD -m5 -M10 -l 7-8 -d2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc9Sm3HE_ook",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58d629d-05ba-42a4-fd09-8d1ef950fa8e"
      },
      "source": [
        "'''\n",
        "  levels: 5-6\n",
        "  index: 1 (in `dataset_tree`)\n",
        "  tree name: gkhood56.tree\n",
        "  cache location: /cache56/\n",
        "'''\n",
        "!python app.py FLD -m3 -M8 -l 5-6 -d2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "operation FLD: generating First-level-Last-level dataset\n",
            "        arguments -> kmin=3, kmax=8, first-level=5, last-level=6, distance=2\n",
            "GKhood instance generated in 00:01:22\n",
            "dataset generated in 00:00:24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI3XR26I4fPT"
      },
      "source": [
        "## peak annotation to sequence\n",
        "\n",
        "`peakseq.py` module is responsible for converting annotation to Sequences for furthur studies. those anotations are in ENCODE format gatherd from [hmChIP](http://jilab.biostat.jhsph.edu/database/cgi-bin/hmChIP.pl)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpjIUFJVEUEV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "060fe1ec-2912-4354-bcc4-515ca77d29c0"
      },
      "source": [
        "!python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak.cod"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[peakseq] making fasta file from cod-annotation peaks (cod=./hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak.cod)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2-mx9a7hJSO"
      },
      "source": [
        "# Motif finding using chain algorithm\n",
        "\n",
        "AKAGI uses a two-phase algorithm descibed below for `MFC` command:\n",
        "\n",
        "## 1) Observation phase\n",
        "\n",
        "At this phase, AKAGI starts to read input sequences in fixed-lenght frames and add every seen kmers to WATCH tree. Finally after a few step of tree searching (BFS), kmers with higher frequencies extracted and stored in a list for next phase\n",
        "\n",
        "## 2) Chaining phase\n",
        "\n",
        "With high-frequency kmers from last phase called **motif**, AKAGI search for possible links between these words to reveal longer patterns. Two parameter **overlap** and **gap** are used at this phase to consider more diffrences for each instance from original pattern at each level. *more successful links, more distanced form pattern a chain could go*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_qBNlsA7ov6"
      },
      "source": [
        "'''\n",
        "  #### biology\n",
        "  input sequences: peaks\n",
        "  sample: A549 cell\n",
        "  treatment: 1h with 500 pM Dexamethasone (Myers)\n",
        "  Antibody Target: NR3C1\n",
        "    The glucocorticoid receptor (GR, or GCR) also known as NR3C1\n",
        "  -> GR binding in lung carcinoma tissue derived epithelial cell line A549 <-\n",
        "  #### application\n",
        "  file size = 13 KB\n",
        "  frame sizes = (5-distance=1), (6-distance=1) - multilayer observation\n",
        "  minimum lexicon limit = 1000 words\n",
        "'''\n",
        "\n",
        "# disk utilization\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_DISK -C BATCH_SIZE=10\n",
        "\n",
        "!python app.py MFC -s peaks/ENCODE_HAIB_A549_Dex500pM_NR3C1_peak -x1000 -Q -t /A1000 -f 5-6 -d 1-1 -G 1-1 -u"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62y5xLq0qOFS"
      },
      "source": [
        "# AKAGI Prediction\n",
        "\n",
        "previously described operations are used to identify repeated motifs with an *edit-distance based* model. Finally each of those found motifs are ranked by AKAGI to determine the best one in term of different observation.\n",
        "\n",
        "- SSMART: or statistical score for each motif that measured by considering peak sequence scores from peak calling tools\n",
        "- SUMMIT: or exprimental score that shows the distance of a motif from peak summit\n",
        "- JASPAR: reference score for evaluating found motif by AKAGI using jaspar database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfDDgfhwqm2a"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#              JUND EXPERIMENT                    #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "# [WARNING] -> specify file types for each attachment -> T: textfile, I: image\n",
        " \n",
        "# expriment description\n",
        "'''\n",
        "  input sequences: ChIP-Seq peaks\n",
        "  sample: GM12878\n",
        "  tissue: blood\n",
        "  Antibody Target: JUND (Transcription Factor)\n",
        "  jaspar index: MA0491.1\n",
        "  chipXpress: -unmeasured-\n",
        "'''\n",
        "\n",
        "# ----------- data preparation ----------- #\n",
        "\n",
        "# reading annotation and make fasta format sequence file\n",
        "!python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_Yale_GM12878_JUND_peak.cod > peakseq.out\n",
        "\n",
        "# store BFS cache data for expriment\n",
        "!python app.py FLD -m4 -M7 -l 5-6 -d1 > FLD56.out\n",
        "\n",
        "# downloading jaspar motif reference\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0491.1.pfm\n",
        " \n",
        "# ----------- AKAGI configuration ----------- #\n",
        "!python app.py NOP -C PARENT_WORK=True\n",
        " \n",
        "# ----------- AKAGI execution ----------- #\n",
        "!python app.py MFC -s hmchipdata/Human_hg18_peakcod/ENCODE_Yale_GM12878_JUND_peak \\\n",
        "  --megalexa 1000               \\\n",
        "  --find-max-q                  \\\n",
        "  --multi-layer                 \\\n",
        "  --frame 3-5-6                 \\\n",
        "  --distance 0-1-1              \\\n",
        "  --gkhood 0-1-1                \\\n",
        "  --gap 4                       \\\n",
        "  --overlap 3                   \\\n",
        "  --multicore                   \\\n",
        "  --ncores 2                    \\\n",
        "  --jaspar pfms/MA0491.1.pfm    \\\n",
        "  > MFC.out\n",
        " \n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i peakseq.out-FLD56.out-MFC.out-clear.out -a chaining_report.window -t T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxUiZYnXZk3Y"
      },
      "source": [
        "# Experiments and Evaluation\n",
        "\n",
        "each expriment aim to find patterns among ChiP-seq data gathered from [hmChip](http://jilab.biostat.jhsph.edu/database/cgi-bin/hmChIP.pl) database that can predict target protein's binding sites. sample references are provided as below. in term of evaluating, each pattern will be measured by already known PWM based motifs from jaspar database in different versions addressed as below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwdfCUMOTNtZ"
      },
      "source": [
        "## SRF Expriment\n",
        "\n",
        "### Description\n",
        "\n",
        "-  input sequences: ChIP-Seq peaks\n",
        "-  sample: [GM12878](https://www.coriell.org/0/Sections/Search/Sample_Detail.aspx?Ref=GM12878)\n",
        "-  tissue: blood\n",
        "-  Antibody Target: [SRF](https://www.uniprot.org/uniprot/P11831) (Transcription Factor)\n",
        "-  jaspar index(s): MA0083 with 3 version\n",
        "\n",
        "  1.   [SELEX](http://jaspar.genereg.net/matrix/MA0083.1/) (*-low* number of sites)\n",
        "  2.   [ChIP-seq](http://jaspar.genereg.net/matrix/MA0083.2/)\n",
        "  3.   [HT-SELEX](http://jaspar.genereg.net/matrix/MA0083.3/)\n",
        "\n",
        "-  chipXpress: (score=12.2, rank=1)\n",
        "\n",
        "### AKAGI results\n",
        "\n",
        "- not calculated yet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ywJowZS5HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e7967b-922d-45d1-fdb4-e3de0d2caaa9"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#              SRF  EXPERIMENT                    #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "# [WARNING] -> specify file types for each attachment -> T: textfile, I: image\n",
        "\n",
        "# ----------- data preparation ----------- #\n",
        "\n",
        "# reading annotation and make fasta format sequence file\n",
        "# !python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak.cod > peakseq.out\n",
        "\n",
        "# store BFS cache data for expriment\n",
        "# !python app.py FLD -m3 -M8 -l 5-6 -d2 > FLD56.out\n",
        "\n",
        "# downloading jaspar motif reference\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0083.2.pfm\n",
        " \n",
        "# ----------- AKAGI configuration ----------- #\n",
        "!python app.py NOP -C PARENT_WORK=True             # parent job\n",
        "!python app.py NOP -C MAX_SEQUENCE_COUNT=100       # briefing sequences\n",
        "!python app.py NOP -C TIMER_CHAINING_HOURS=4       # set up 6 hour timer\n",
        "!python app.py NOP -C SAVE_OBSERVATION_CLOUD=True  # uploading observation result (ON)\n",
        "!python app.py NOP -C SAVE_THE_REST_CLOUD=False    # rest of work checkpoints (LOCAL)\n",
        "!python app.py NOP -C NEED_HELP=100000             # send help signal\n",
        "!python app.py NOP -C ON_SEQUENCE_ANALYSIS=False   # on sequence analysis (OFF)\n",
        "\n",
        "# ----------- AKAGI execution ----------- #\n",
        "!mprof run python app.py MFC -s hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak \\\n",
        "  --megalexa 1000               \\\n",
        "  --find-max-q                  \\\n",
        "  --multi-layer                 \\\n",
        "  --frame 5-6                   \\\n",
        "  --distance 1-2                \\\n",
        "  --gkhood 1-1                  \\\n",
        "  --gap 4                       \\\n",
        "  --overlap 3                   \\\n",
        "  --multicore                   \\\n",
        "  --ncores 2                    \\\n",
        "  --jaspar pfms/MA0083.2.pfm\n",
        "  \n",
        "!mprof plot -o memory.png\n",
        " \n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i peakseq.out-MFC.out-clear.out --re-p -a chaining_report.window-memory.png -t T-I"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mprof: Sampling memory every 0.1s\n",
            "running new process\n",
            "operation MFC: finding motif using chain algorithm (tree_index(s):[1, 1])\n",
            "        arguments -> f(s)=[5, 6], q=-2, d(s)=[1, 2], gap=4, overlap=3, dataset=hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak\n",
            "        operation mode: False; coloring_frame=-1; multi-layer=True; megalexa=1000\n",
            "[FOUNDMAP] foundmap mode: disk\n",
            "[BRIEFING] number of sequences = 100\n",
            "(len:400,score:8.486294) (len:400,score:8.466699) (len:400,score:7.986474) (len:400,score:7.867773) (len:400,score:7.759249) (len:400,score:7.614328) (len:400,score:7.612467) (len:400,score:7.256706) (len:400,score:7.161123) (len:400,score:7.035571) (len:400,score:7.020070) (len:400,score:6.959688) (len:400,score:6.847917) (len:315,score:6.801447) (len:400,score:6.762850) (len:400,score:6.745471) (len:315,score:6.705765) (len:400,score:6.580359) (len:400,score:6.566410) (len:400,score:6.535247) (len:400,score:6.476416) (len:400,score:6.469121) (len:400,score:6.436924) (len:400,score:6.424141) (len:400,score:6.386981) (len:400,score:6.369400) (len:400,score:6.353715) (len:315,score:6.231055) (len:400,score:6.226339) (len:400,score:6.221990) (len:400,score:6.218089) (len:400,score:6.187519) (len:400,score:6.144306) (len:400,score:6.139471) (len:400,score:6.104720) (len:400,score:6.094309) (len:400,score:6.083800) (len:400,score:6.075421) (len:400,score:6.072557) (len:400,score:6.069177) (len:400,score:6.037110) (len:400,score:6.019830) (len:400,score:6.003796) (len:400,score:5.998534) (len:400,score:5.977309) (len:400,score:5.976100) (len:400,score:5.954824) (len:400,score:5.952366) (len:400,score:5.935167) (len:400,score:5.924008) (len:400,score:5.899587) (len:400,score:5.881471) (len:400,score:5.871230) (len:400,score:5.863190) (len:400,score:5.860737) (len:400,score:5.852016) (len:400,score:5.841497) (len:400,score:5.823659) (len:400,score:5.785858) (len:400,score:5.767807) (len:400,score:5.720377) (len:400,score:5.704685) (len:400,score:5.703899) (len:400,score:5.703362) (len:400,score:5.695484) (len:400,score:5.687278) (len:400,score:5.668122) (len:400,score:5.667677) (len:400,score:5.667274) (len:400,score:5.646130) (len:400,score:5.634250) (len:400,score:5.613217) (len:400,score:5.603210) (len:400,score:5.595769) (len:400,score:5.577618) (len:315,score:5.571695) (len:400,score:5.543961) (len:400,score:5.542087) (len:400,score:5.516658) (len:400,score:5.516638) (len:400,score:5.512328) (len:400,score:5.478711) (len:400,score:5.457660) (len:400,score:5.449783) (len:400,score:5.443114) (len:400,score:5.406788) (len:400,score:5.387600) (len:400,score:5.380616) (len:400,score:5.378568) (len:398,score:5.353753) (len:315,score:5.302275) (len:400,score:5.298552) (len:400,score:5.276791) (len:400,score:5.265491) (len:400,score:5.265079) (len:400,score:5.256736) (len:400,score:5.246984) (len:400,score:5.238538) (len:400,score:5.217531) (len:400,score:5.214110) \n",
            "[CHECK-POINT] checkpoint doesn't exist\n",
            "[find_max_q] q = 100\n",
            "\n",
            "number of motifs->9410 | execute time->01:31:32\n",
            "[lexicon] lexicon size = 9410\n",
            "[CLOUD] number of protected files to be compressed: 9410\n",
            "[CLOUD] compressing directory - total bytes count: 110914156 (105.77598190307617 MB)\n",
            "[UPLOAD] WARNING: starting to upload a large file\n",
            "Traceback (most recent call last):\n",
            "  File \"app.py\", line 533, in <module>\n",
            "    checkpoint=args_dict['checkpoint'])\n",
            "  File \"app.py\", line 168, in motif_finding_chain\n",
            "    if cloud:store_checkpoint_to_cloud(checkpoint_file, protected_directory)\n",
            "  File \"/content/AKAGI/googledrive.py\", line 107, in store_checkpoint_to_cloud\n",
            "    compressed_drive.Upload()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/files.py\", line 285, in Upload\n",
            "    self._FilesInsert(param=param)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\", line 75, in _decorated\n",
            "    return decoratee(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/files.py\", line 369, in _FilesInsert\n",
            "    http=self.http)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\", line 879, in execute\n",
            "    _, body = self.next_chunk(http=http, num_retries=num_retries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\", line 1058, in next_chunk\n",
            "    self.resumable_uri, method=\"PUT\", body=data, headers=headers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/oauth2client/transport.py\", line 175, in new_request\n",
            "    redirections, connection_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/oauth2client/transport.py\", line 282, in request\n",
            "    connection_type=connection_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/httplib2/__init__.py\", line 1991, in request\n",
            "    cachekey,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/httplib2/__init__.py\", line 1690, in _request\n",
            "    content,\n",
            "httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.\n",
            "Using last profile data.\n",
            "[MAIL][ERROR] file doesn't exist (peakseq.out)\n",
            "[MAIL][ERROR] file doesn't exist (MFC.out)\n",
            "[MAIL][ERROR] file doesn't exist (clear.out)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNGyKbeIRhKx"
      },
      "source": [
        "## CEBPB Expriment\n",
        "\n",
        "### Description\n",
        "\n",
        "-  input sequences: ChIP-Seq peaks\n",
        "-  sample: [HepG2](https://www.atcc.org/products/all/HB-8065.aspx)\n",
        "-  tissue: liver\n",
        "-  Antibody Target: [CEBPB](https://www.uniprot.org/uniprot/P17676) (Transcription Factor)\n",
        "-  jaspar index(s): MA0466 with 2 version\n",
        "  -    1: [ChIP-seq](http://jaspar.genereg.net/matrix/MA0466.1/)\n",
        "  -    2: [HT-SELEX](http://jaspar.genereg.net/matrix/MA0466.2/)\n",
        "-  chipXpress: (score=4.7, rank=1)\n",
        "\n",
        "### AKAGI results\n",
        "\n",
        "- not calculated yet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GCRkLmLL_n",
        "outputId": "2a77acb7-81db-4ade-c968-3bcecd888950"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#              CEBPB  EXPERIMENT                  #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "# [WARNING] -> specify file types for each attachment -> T: textfile, I: image\n",
        "\n",
        "# ----------- data preparation ----------- #\n",
        "\n",
        "# reading annotation and make fasta format sequence file\n",
        "!python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_Stanford_HepG2_CEBPB_peak.cod > peakseq.out\n",
        "\n",
        "# store BFS cache data for expriment\n",
        "!python app.py FLD -m3 -M8 -l 5-6 -d2 > FLD56.out\n",
        "\n",
        "# downloading jaspar motif reference\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0466.1.pfm\n",
        " \n",
        "# ----------- AKAGI configuration ----------- #\n",
        "!python app.py NOP -C PARENT_WORK=False -C MAX_SEQUENCE_COUNT=100\n",
        " \n",
        "# ----------- AKAGI execution ----------- #\n",
        "!timeout 8h mprof run python app.py MFC -s hmchipdata/Human_hg18_peakcod/ENCODE_Stanford_HepG2_CEBPB_peak \\\n",
        "  --megalexa 1000               \\\n",
        "  --find-max-q                  \\\n",
        "  --multi-layer                 \\\n",
        "  --frame 3-5                   \\\n",
        "  --distance 0-2                \\\n",
        "  --gkhood 0-1                  \\\n",
        "  --gap 4                       \\\n",
        "  --overlap 3                   \\\n",
        "  --multicore                   \\\n",
        "  --ncores 2                    \\\n",
        "  --jaspar pfms/MA0466.1.pfm    \\\n",
        "  > MFC.out\n",
        "!mprof plot -o memory.png\n",
        "\n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i peakseq.out-FLD56.out-MFC.out-clear.out -a chaining_report.window-memory.png -t T-I"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using last profile data.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQvIMkWmtk-I"
      },
      "source": [
        "## SREBF1 Expriment\n",
        "\n",
        "### Description\n",
        "\n",
        "*   input sequences: ChIP-seq peaks\n",
        "*   sample: [HepG2](https://www.atcc.org/products/all/HB-8065.aspx)\n",
        "*   tissue: liver\n",
        "*   Antibody Target: [SREBF1](https://www.uniprot.org/uniprot/P36956) Sterol regulatory element-binding protein 1\n",
        "  *   Precursor of the transcription factor form (Processed sterol regulatory element-binding protein 1)\n",
        "*   Jaspar index(es): MA0829 with 2 version and MA0595.1\n",
        "  *   1: [HT-SELEX](http://jaspar.genereg.net/matrix/MA0829.1/)\n",
        "  *   2: [ChIP-seq](http://jaspar.genereg.net/matrix/MA0829.2/)\n",
        "  *   [MA0595.1](http://jaspar2018.genereg.net/matrix/MA0595.1/) *ChIP-seq*\n",
        "*   chipXpress: (score=7.2, rank=1)\n",
        "\n",
        "### AKAGI results\n",
        "\n",
        "*   not calculated yet\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qktZPDMLvkiQ"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#              SREBF1  EXPERIMENT                 #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "# [WARNING] -> specify file types for each attachment -> T: textfile, I: image\n",
        "\n",
        "# ----------- data preparation ----------- #\n",
        "\n",
        "# reading annotation and make fasta format sequence file\n",
        "!python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_Yale_HepG2_SREBF1_peak.cod > peakseq.out\n",
        "\n",
        "# store BFS cache data for expriment\n",
        "!python app.py FLD -m3 -M8 -l 5-6 -d2 > FLD56.out\n",
        "\n",
        "# downloading jaspar motif reference\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0595.1.pfm\n",
        " \n",
        "# ----------- AKAGI configuration ----------- #\n",
        "!python app.py NOP -C PARENT_WORK=True -C MAX_SEQUENCE_COUNT=100\n",
        " \n",
        "# ----------- AKAGI execution ----------- #\n",
        "!timeout 8h mprof run python app.py MFC                          \\\n",
        "  -s hmchipdata/Human_hg18_peakcod/ENCODE_Yale_HepG2_SREBF1_peak \\\n",
        "  --megalexa 1000               \\\n",
        "  --find-max-q                  \\\n",
        "  --multi-layer                 \\\n",
        "  --frame 3-6                   \\\n",
        "  --distance 0-2                \\\n",
        "  --gkhood 0-1                  \\\n",
        "  --gap 4                       \\\n",
        "  --overlap 3                   \\\n",
        "  --multicore                   \\\n",
        "  --ncores 2                    \\\n",
        "  --jaspar pfms/MA0595.1.pfm    \\\n",
        "  > MFC.out\n",
        "!mprof plot -o memory.png\n",
        " \n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i peakseq.out-FLD56.out-MFC.out-clear.out -a chaining_report.window-memory.png-parent.report -t T-I-T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Skqxu_XDRIV2"
      },
      "source": [
        "# Check Point\n",
        "\n",
        "AKAGI uses `checkpoints.py` module to save and load unfinihsed jobs or store precalculated data in case of other application instances may need them. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXvPnw5YVsD2"
      },
      "source": [
        "## Resumable check-points\n",
        "\n",
        "an instance of application is able to resume remaining jobs with having `dataset_name`, on sequence distribution of first generation motifs and `q` value. overlap and gap options can be different for application instances. calling the `RCH` command, make AKAGI search for resuamable checkpoints offline or in cloud and resuam it\n",
        "\n",
        "in case of having a working parent instead of memory-balancing one, the parent process will save and send a portion of working queue as resuamable checkpoints to **call for help** from another avaiable AKAGI instances. each instnace eventually report their best ranking by email and its up to user to choose between them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYZZ1ghcVs4W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd3509fc-c54c-4f04-d483-5d9e13c112c8"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        " \n",
        "#              HELP and RESUME                    #\n",
        " \n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# ----------- AKAGI configuration ----------- #\n",
        "# !python app.py NOP -C PARENT_WORK=True        # parent job\n",
        "# !python app.py NOP -C MAX_SEQUENCE_COUNT=100  # briefing sequences\n",
        "# !python app.py NOP -C TIMER_CHAINING_HOURS=4  # set up 8 hour timer\n",
        "\n",
        "!python app.py RCH -n2 -O3 -g4\n",
        "\n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i clear.out -a chaining_report.window -t T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CLOUD] download is done in 0:00:07.631784 time\n",
            "[peakseq] making fasta file from cod-annotation peaks (cod=hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak.cod)\n",
            "[ERROR]\tb'\\x00\\x00\\x00d'\t<class 'bytes'>\n",
            "[ERROR] something went wrong when sending help\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX7BBLdg0lud"
      },
      "source": [
        "## Observation check-point\n",
        "\n",
        "Exploring such hidden patterns may require many execution with different set of parameters for better chaining or just better undrestanding study. storing the observation phase data in cloud services helps AKAGI to use first generation of motifs (also called *zero motifs*) found by another execution before. by raising `-k` or `--check-point` flag, AKAGI runs in check-point mode\n",
        "\n",
        "**making / loading**: whenever any execution of AKAGI reaches the observation point with check-point flag on, it will search for an existing check-point in disk. if no check-point exist for application goal then after computing observation phase, AKAGI will protect and store the results as check-point for furthur use.\n",
        "\n",
        "**cloud**: check-points can be stored at google drive with `UOC` and can be downloaded later with `DOC` command. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53RgW4UBC2h3"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "!python app.py NOP -C SAVE_OBSERVATION_CLOUD=True # uploading observation result\n",
        "\n",
        "last = datetime.now()\n",
        "!mprof run python app.py MFC -s hmchipdata/Human_hg18_peakcod/ENCODE_HAIB_GM12878_SRF_peak \\\n",
        "  --megalexa 1000               \\\n",
        "  --find-max-q                  \\\n",
        "  --multi-layer                 \\\n",
        "  --frame 5-6                   \\\n",
        "  --distance 1-2                \\\n",
        "  --gkhood 1-1                  \\\n",
        "  --disable-chaining            \\\n",
        "  --jaspar pfms/MA0083.2.pfm\n",
        "print(datetime.now() - last)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5pBLp2be_zQ",
        "outputId": "3f7f08f9-f92a-4f0c-9900-9dde179494e1"
      },
      "source": [
        "# <  SREBF1 EXPERIMENT  > \n",
        "\n",
        "# reading annotation and make fasta format sequence file\n",
        "!python peakseq.py -c ./hmchipdata/Human_hg18_peakcod/ENCODE_Yale_HepG2_SREBF1_peak.cod > peakseq.out\n",
        "\n",
        "# store BFS cache data for expriment\n",
        "!python app.py FLD -m3 -M8 -l 5-6 -d2 > FLD56.out\n",
        "\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0595.1.pfm\n",
        "\n",
        "!python app.py MFC --disable-chaining \\\n",
        "  -s hmchipdata/Human_hg18_peakcod/ENCODE_Yale_HepG2_SREBF1_peak  \\\n",
        "  -f 3-5                                                          \\\n",
        "  -d 0-2                                                          \\\n",
        "  -u                                                              \\\n",
        "  --gkhood 0-1                                                    \\\n",
        "  --jaspar pfms/MA0595.1.pfm                                      \\\n",
        "  > MFC.out\n",
        "\n",
        "!python app.py UCP                                                \\\n",
        "  -s hmchipdata/Human_hg18_peakcod/ENCODE_Yale_HepG2_SREBF1_peak  \\\n",
        "  -f 3-5 \\\n",
        "  -d 0-2 \\\n",
        "  -u     \n",
        "\n",
        "# ----------- clear & report ----------- #\n",
        "!python FoundMap.py > clear.out\n",
        "!python report_email.py -i peakseq.out-FLD56.out-MFC.out-clear.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|####################| 6233/6233\n",
            "done uploading\n",
            "[MAIL][ERROR] file doesn't exist (FLD.out)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrvCQTijypjh"
      },
      "source": [
        "# Memory Profiling \n",
        "\n",
        "experiment goal: monitoring memory usage between differente foundmap operational mode (disk vs memory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYiQ5BX213GD"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "#               EXPERIMENT .1                     #\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "\n",
        "# data description\n",
        "'''\n",
        "  #### biology\n",
        "  input sequences: peaks\n",
        "  sample: HUVEC (umbilical vein endothelial cells)\n",
        "  tissue: blood vessel\n",
        "  lab: Broad\n",
        "  Antibody Target: H3K4me1\n",
        "    description: Histone H3 (mono methyl K4). Is associated with enhancers, and downstream of transcription starts\n",
        "  -> H3K4me1 in HUVEC umbilical vein endothelial cells <-\n",
        "  #### application\n",
        "  file size = 229 KB\n",
        "  frame sizes = (7-distance=1)\n",
        "  minimum lexicon limit = 1000 words\n",
        "'''\n",
        "\n",
        "# first, runing BFS cache generator - profiling memory for estimating the size of gkmerhood\n",
        "!mprof run python app.py FLD -m4 -M7 -l 5-6 -d1 > FLD56.out\n",
        "!mprof plot -o FLD_mprof_56.png\n",
        "\n",
        "# only memory configuration\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_MEMO\n",
        "\n",
        "!mprof run python app.py MFC -s peaks/ENCODE_Broad_HUVEC_H3K9me1_peak -x1000 -Q -t /DISKSINGLE -f 5-6 -d 1-1 -G 1-1 -u --disable-chaining > HUVEC_H3_run.out\n",
        "!mprof plot -o HUVEC_H3_run_foundmap_memory.png\n",
        "\n",
        "# disk utilization\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_DISK -C BATCH_SIZE=10\n",
        "\n",
        "!mprof run python app.py MFC -s peaks/ENCODE_Broad_HUVEC_H3K9me1_peak -x1000 -Q -t /DISKSINGLE -f 5-6 -d 1-1 -G 1-1 -u --disable-chaining > HUVEC_H3_run_2.out\n",
        "!mprof plot -o HUVEC_H3_run_foundmap_disk10.png\n",
        "\n",
        "# Email reports include memory usage of in-memory and hybrid disk-memory version of AKAGI and clean\n",
        "!mprof clean\n",
        "!python FoundMap.py > other.out # clean foundmap temp\n",
        "!python report_email.py -i FLD.out-HUVEC_H3_run.out-HUVEC_H3_run_2.out-other.out -a FLD_mprof_56.png-HUVEC_H3_run_foundmap_memory.png-HUVEC_H3_run_foundmap_disk10.png\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1LVjCMy8hxK"
      },
      "source": [
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "#               EXPERIMENT .2                     #\n",
        "\n",
        "# # # # # # # # # # # # # # # # # # # # # # # # # #\n",
        "\n",
        "# [WARNING] -> `secret.json` is required for auto-email\n",
        "\n",
        "# data description\n",
        "'''\n",
        "  #### biology\n",
        "  input sequences: peaks\n",
        "  sample: HUVEC (umbilical vein endothelial cells)\n",
        "  tissue: blood vessel\n",
        "  lab: Broad\n",
        "  Antibody Target: H3K4me1\n",
        "    description: Histone H3 (mono methyl K4). Is associated with enhancers, and downstream of transcription starts\n",
        "  -> H3K4me1 in HUVEC umbilical vein endothelial cells <-\n",
        "  #### application\n",
        "  file size = 229 KB\n",
        "  frame sizes = (7-distance=1)\n",
        "  minimum lexicon limit = 1000 words\n",
        "'''\n",
        "\n",
        "# first, runing BFS cache generator\n",
        "!python app.py FLD -m4 -M7 -l 5-6 -d1 > FLD56.out\n",
        "\n",
        "# configuration (BATCH=1)\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_DISK -C BATCH_SIZE=1\n",
        "\n",
        "!mprof run python app.py MFC -s peaks/ENCODE_Broad_HUVEC_H3K9me1_peak -Q -f 5-6 -d 1-1 -G 1-1 -u --disable-chaining > HUVEC_H3_run_1.out\n",
        "!mprof plot -o HUVEC_H3_run_batch1.png\n",
        "\n",
        "# configuration (BATCH=10)\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_DISK -C BATCH_SIZE=10\n",
        "\n",
        "!mprof run python app.py MFC -s peaks/ENCODE_Broad_HUVEC_H3K9me1_peak -Q -f 5-6 -d 1-1 -G 1-1 -u --disable-chaining > HUVEC_H3_run_2.out\n",
        "!mprof plot -o HUVEC_H3_run_batch10.png\n",
        "\n",
        "# Email reports include same task with different batch size\n",
        "!mprof clean\n",
        "!python FoundMap.py > other.out # clean foundmap temp\n",
        "!python report_email.py -i FLD56.out-HUVEC_H3_run_1.out-HUVEC_H3_run_2.out-other.out -a HUVEC_H3_run_batch1.png-HUVEC_H3_run_batch10.png\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWIlNQZcwSl7"
      },
      "source": [
        "# profiling cache generator\n",
        "!mprof run python app.py FLD -m5 -M10 -l 7-8 -d2 > output.out\n",
        "!mprof plot -o FLD_mprof_78.png\n",
        "\n",
        "!python report_email.py -i output.out -a FLD_mprof_78.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69dbO3hwzOPI"
      },
      "source": [
        "# cleaning memory profile data\n",
        "!mprof clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV_q-gTakZ4D"
      },
      "source": [
        "# *Big data?* - Disk Utilization\n",
        "\n",
        "## Observation phase\n",
        "\n",
        "We observed some entry of our dataset contains many sequences which required so much memory to save all observations. `FoundMap.py` Module is resposible for hybrid memory-disk utilization to handle big data. By using `foundmap` class, AKAGI saves observation data (sequence id, position and margin) in memory until it reaches `BATCH_SIZE` limit. For memory and disk integration, `FileMap.FileHandler` class is implemented to convert information into byte stream and reverse, enabling the application to read, update and save data between disk and memory\n",
        "\n",
        "## Chaining phase\n",
        "\n",
        "Even though `foundmap` is stored in disk, keeping many `ChainNode` in memory may results in overflow. as the rate of producing new generation needed to be chained is much higher than processing each chain, it is needed to store those objects in disk. DiskQueue is implemented for this purpose and the parent process is responsible to manage this queue for balancing memory. on the other hand in case of more cores for multiprocessing there is no need for balancing memory when cores are able to process chains in near the rate of producing new generations so parent process also can join other workers as well for multiprocessing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6I0xfNnvlB"
      },
      "source": [
        "# AKAGI disk utilization config\n",
        "!python app.py NOP -C FOUNDMAP_MODE=FOUNDMAP_DISK -C BATCH_SIZE=100 -C PARENT_WORK=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrDLpfKC1IUj"
      },
      "source": [
        "# for clearing disk\n",
        "!python FoundMap.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWAJO9tV13tB"
      },
      "source": [
        "# useful cells commands for development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPSXGxhHAhUf"
      },
      "source": [
        "# downloading PFM from jaspar using link\n",
        "!wget -q -P ./pfms http://jaspar.genereg.net/api/v1/matrix/MA0491.1.pfm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EZfGeuQBGWe",
        "outputId": "8f440d3d-9f0e-48bb-a56c-cc97d219af51"
      },
      "source": [
        "import os\n",
        "print(os.cpu_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zILHTMCQGe1p",
        "outputId": "9b2a675d-d084-4465-bb98-99ff39a83678"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "exec(urlopen(\"http://colab-monitor.smankusors.com/track.py\").read())\n",
        "_colabMonitor = ColabMonitor().start()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now live at : http://colab-monitor.smankusors.com/6068c01af3294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x7d1lwTaI-u"
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gq9jpzBiBNqG"
      },
      "source": [
        "!timeout 5s mprof run python t.py\n",
        "!mprof plot -o a.png"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0j5q8ryEoaum",
        "outputId": "fa3d7da3-97f9-4673-e0fa-8401ba74c21c"
      },
      "source": [
        "from datetime import datetime\n",
        "print(datetime.now())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-21 20:08:40.707233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT5S_t_ZKLmq",
        "outputId": "1f8e5604-612a-4a8b-85b5-53e52519b70f"
      },
      "source": [
        "%cd AKAGI"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'AKAGI'\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0HesYBgKSw6",
        "outputId": "21125598-925b-4eba-c29f-6b5b08256ecf"
      },
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "gauth = GoogleAuth()\n",
        "gauth.CommandLineAuth()\n",
        "\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to the following link in your browser:\n",
            "\n",
            "    https://accounts.google.com/o/oauth2/auth?client_id=285671014364-v2c9m48chkqi23e33phpoodrjfugjvop.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
            "\n",
            "Enter verification code: 4/1AY0e-g4pBJT-qUXKpefopOIU_ppnqX0KQ1Y6-6jqwxs_TYRcdeOGWwyzQ9g\n",
            "Authentication successful.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uElkeKKE4_Gw"
      },
      "source": [
        "!ps -aus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvQc2lnk5dLi",
        "outputId": "c69dda34-c720-4614-e34f-71fcc12f1a21"
      },
      "source": [
        "!python googledrive.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLOUD] number of protected files to be compressed: 9410\n",
            "[CLOUD] compressing directory - total bytes count: 110914156 (105.77598190307617 MB)\n",
            "[UPLOAD] WARNING: starting to upload a large file\n",
            "Traceback (most recent call last):\n",
            "  File \"googledrive.py\", line 148, in <module>\n",
            "    store_checkpoint_to_cloud('ENCODE_HAIB_GM12878_SRF_peak_f5-6_d1-2.checkpoint', 'appdata/ENCODE_HAIB_GM12878_SRF_peak_f5-6_d1-2/')\n",
            "  File \"googledrive.py\", line 107, in store_checkpoint_to_cloud\n",
            "    compressed_drive.Upload()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/files.py\", line 285, in Upload\n",
            "    self._FilesInsert(param=param)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/auth.py\", line 75, in _decorated\n",
            "    return decoratee(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pydrive/files.py\", line 369, in _FilesInsert\n",
            "    http=self.http)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\", line 879, in execute\n",
            "    _, body = self.next_chunk(http=http, num_retries=num_retries)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\", line 134, in positional_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\", line 1058, in next_chunk\n",
            "    self.resumable_uri, method=\"PUT\", body=data, headers=headers\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/oauth2client/transport.py\", line 175, in new_request\n",
            "    redirections, connection_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/oauth2client/transport.py\", line 282, in request\n",
            "    connection_type=connection_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/httplib2/__init__.py\", line 1991, in request\n",
            "    cachekey,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/httplib2/__init__.py\", line 1690, in _request\n",
            "    content,\n",
            "httplib2.RedirectMissingLocation: Redirected but the response is missing a Location: header.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}